- 과제 
1. 28, 29, 30, 31


Dense  2차원  input_shape = (1, )
LSTM   3차원  input_shape = (3, 1)
CNN    4차원  input_shape = (5, 3, 1)

x = datasets[:,0:4] : 모든행을 앞에서부터 4개씩 잘라서 x에 넣는다.
y = datasets[:,4]   : 모든행을 인덱스 4번째만 잘라서 y에 넣는다.          


model.save('save1.h5') : 모델을 저장할 수 있다.
                             : 이름이 save1이고 확장자 h5를 가진 파일로 저장된다.
                             : VScode는 경로를 지정해주지 않으면 
                               현재 폴더부터 가장 root에 저장한다 
                             : model.save('./save/keras28_1.h5')
                             : model.save('.//save//keras28_2.h5')
                             : model.save('.\save\keras28_3.h5')
                             : model.save('.\\save\\keras28_4.h5')

import load_model : 저장된 모델을 불러 올 수 있다.
                         : model = load_model("./save/keras28_1.h5") 로 불러 올 수 있다
                         : model.add 를 통하여 불러온 모델에 layer를 추가할 수 있다.
                         : 불러온 모델에 layer를 추가하려면 이름을 지정해줘야한다.


history = model.fit() -
history.history.keys() => dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])


# 그래프
import matplotlib.pyplot as plt  
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])

plt.title('loss & mae')
plt.ylabel('loss , mae')
plt.xlabel('epochs')

plt.legend(['train loss','val loss','train mae','val mae'])
plt.show()



tensorboard
	: from tensorflow.keras.callbacks import TensorBoard
	: tb = TensorBoard(log_dir='graph',histogram_freq=0,
	                        write_graph=True, write_images=True) 
	: log_dir='graph' : log가 들어갈 폴더를 지정해라
                 
cmd에서 실행 => tensorboard --logdir=.


# 데이터 전처리 
                     : 최대값으로 나눈다.
                     : x만 전처리하여 계산을 쉽게한다
                     : 최소값이 0이 아닐때 (X/최대값 - 최소값)
                     : from sklearn.preprocessing import MinMaxScaler
	           scaler = MinMaxScaler()
                       scaler.fit(x)
                       x = scaler.transform(x)
                       x_predict = scaler.transform(x_predict) 
                       => x의 전처리 기준값으로  x_predict 전처리한다.
                     : 예측해야하는 값이 준비된 훈련값보다 클지라도 scaler에 넣어준다.

# Scaler : 전처리에 사용됨
MinMaxScaler() : 최대/최소값이 각각 1, 0이 되도록 스케일링
                    : 이 추정기는 학습 세트의 주어진 범위 
                     (예 : 0과 1 사이)에 있도록 각 특성을 개별적으로 확장하고 변환합니다.
                     
StandardScaler()  : 기본 스케일. 평균과 표준편차 사용
                      : 평균을 제거하고 단위 분산으로 스케일링하여 기능 표준화
                      : (z = (x-mean)/std) -> 표준화 = (x값-x평균값)/x표준편차
                        여기서 u는 훈련 표본의 평균이거나 (with_mean=False)일 경우 0이고, 
                        s는 훈련 표본의 표준 편차 또는 만약(with_std=False)일 경우 1이다.

RobustScaler() : StandardScaler와 비슷 하지만 평균과 분산대신 
                    중간값(median)과 사분위값(quartile)을 사용
                   : 중앙값을 제거하고 분위수 범위(기본값 : IQR)에 따라 데이터를 조정합니다.
                   : 변산도의 일종으로 분포의 양끝 1/4을 제외한 범위이다. 
                   : IQR(Interquartile Range) : 사분범위 
                   : (중앙값=>0) (IQR=>1)이 되도록 변환
                   

MaxAbsScaler() : 최대절대값과 0이 각각 1, 0이 되도록 스케일링 
                    : 각 특성의 최대 절대 값이 1.0이되도록 개별적으로 확장하고 변환합니다. 
                      데이터를 이동 / 중심화하지 않으므로 희소성을 파괴하지 않습니다. 













